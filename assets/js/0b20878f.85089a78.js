"use strict";(self.webpackChunktest=self.webpackChunktest||[]).push([[544],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>m});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var i=a.createContext({}),c=function(e){var t=a.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},u=function(e){var t=c(e.components);return a.createElement(i.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=c(n),m=r,f=p["".concat(i,".").concat(m)]||p[m]||d[m]||o;return n?a.createElement(f,s(s({ref:t},u),{},{components:n})):a.createElement(f,s({ref:t},u))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,s=new Array(o);s[0]=p;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l.mdxType="string"==typeof e?e:r,s[1]=l;for(var c=2;c<o;c++)s[c]=n[c];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},8215:(e,t,n)=>{n.d(t,{Z:()=>r});var a=n(7294);const r=function({children:e,hidden:t,className:n}){return a.createElement("div",{role:"tabpanel",hidden:t,className:n},e)}},6396:(e,t,n)=>{n.d(t,{Z:()=>p});var a=n(7462),r=n(7294),o=n(2389),s=n(9443);const l=function(){const e=(0,r.useContext)(s.Z);if(null==e)throw new Error('"useUserPreferencesContext" is used outside of "Layout" component.');return e};var i=n(3810),c=n(6010);const u="tabItem_vU9c";function d(e){const{lazy:t,block:n,defaultValue:a,values:o,groupId:s,className:d}=e,p=r.Children.map(e.children,(e=>{if((0,r.isValidElement)(e)&&void 0!==e.props.value)return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})),m=o??p.map((({props:{value:e,label:t}})=>({value:e,label:t}))),f=(0,i.lx)(m,((e,t)=>e.value===t.value));if(f.length>0)throw new Error(`Docusaurus error: Duplicate values "${f.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`);const b=null===a?a:a??p.find((e=>e.props.default))?.props.value??p[0]?.props.value;if(null!==b&&!m.some((e=>e.value===b)))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${b}" but none of its children has the corresponding value. Available values are: ${m.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);const{tabGroupChoices:h,setTabGroupChoices:g}=l(),[y,v]=(0,r.useState)(b),w=[],{blockElementScrollPositionUntilNextRender:k}=(0,i.o5)();if(null!=s){const e=h[s];null!=e&&e!==y&&m.some((t=>t.value===e))&&v(e)}const x=e=>{const t=e.currentTarget,n=w.indexOf(t),a=m[n].value;a!==y&&(k(t),v(a),null!=s&&g(s,a))},T=e=>{let t=null;switch(e.key){case"ArrowRight":{const n=w.indexOf(e.currentTarget)+1;t=w[n]||w[0];break}case"ArrowLeft":{const n=w.indexOf(e.currentTarget)-1;t=w[n]||w[w.length-1];break}}t?.focus()};return r.createElement("div",{className:"tabs-container"},r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,c.Z)("tabs",{"tabs--block":n},d)},m.map((({value:e,label:t})=>r.createElement("li",{role:"tab",tabIndex:y===e?0:-1,"aria-selected":y===e,className:(0,c.Z)("tabs__item",u,{"tabs__item--active":y===e}),key:e,ref:e=>w.push(e),onKeyDown:T,onFocus:x,onClick:x},t??e)))),t?(0,r.cloneElement)(p.filter((e=>e.props.value===y))[0],{className:"margin-vert--md"}):r.createElement("div",{className:"margin-vert--md"},p.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==y})))))}function p(e){const t=(0,o.Z)();return r.createElement(d,(0,a.Z)({key:String(t)},e))}},8811:(e,t,n)=>{n.r(t),n.d(t,{frontMatter:()=>l,contentTitle:()=>i,metadata:()=>c,toc:()=>u,default:()=>p});var a=n(7462),r=(n(7294),n(3905)),o=n(6396),s=n(8215);const l={sidebar_position:2},i="Backend Integration",c={unversionedId:"frontend/new-global-action/backend",id:"frontend/new-global-action/backend",title:"Backend Integration",description:"1. Update",source:"@site/docs/frontend/new-global-action/backend.md",sourceDirName:"frontend/new-global-action",slug:"/frontend/new-global-action/backend",permalink:"/I2T-docs/frontend/new-global-action/backend",editUrl:"https://github.com/I2Tunimib/I2T-docs/docs/frontend/new-global-action/backend.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Introduction",permalink:"/I2T-docs/frontend/new-global-action/introduction"},next:{title:"Frontend Integration",permalink:"/I2T-docs/frontend/new-global-action/frontend"}},u=[{value:"1. Update",id:"1-update",children:[],level:3},{value:"2. Create",id:"2-create",children:[],level:3}],d={toc:u};function p({components:e,...t}){return(0,r.kt)("wrapper",(0,a.Z)({},d,t,{components:e,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"backend-integration"},"Backend Integration"),(0,r.kt)("h3",{id:"1-update"},"1. Update"),(0,r.kt)(o.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"autoAnnotation",label:"Automatic Annotation",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js",metastring:'title="src/api/controllers/datasets.controller.js"',title:'"src/api/controllers/datasets.controller.js"'},"...\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js",metastring:'title="src/api/routes/datasets.route.js"',title:'"src/api/routes/datasets.route.js"'},"...\n"))),(0,r.kt)(s.Z,{value:"exportTable",label:"Export Table",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js",metastring:'title="src/api/controllers/datasets.controller.js"',title:'"src/api/controllers/datasets.controller.js"'},'import ExportService from "../services/export/export.service.js";\n\nconst DatasetsController = {\n  ...,\n  exportTable: async (req, res, next) => {\n    const { idDataset, idTable } = req.params;\n    const { format = "w3c", keepMatching = false } = req.query;\n    try {\n      const table = await DatasetsService.findTable(idDataset, idTable);\n      const data = await ExportService[format]({ ...table, keepMatching });\n      res.send(data);\n    } catch (err) {\n      next(err);\n    }\n  },\n  exportTableCode: async (req, res, next) => {\n    const { idDataset, idTable } = req.params;\n    const { format = "python" } = req.query;\n    try {\n      const user = AuthService.verifyToken(req);\n      const dataset = await DatasetsService.findOneDataset(idDataset);\n\n      if (dataset.userId !== user.id) {\n        return res.status(401).json({});\n      }\n\n      // Table existence isn\'t checked - we only need the logs\n      // The table ID is just used for reference in the generated code\n      // Get the exported code file\n      const { data, fileName, contentType } = await ExportService.semtParser({\n        id: idTable,\n        datasetId: idDataset,\n        format: format === "notebook" ? "notebook" : "python",\n      });\n\n      // Set appropriate headers for file download\n      res.setHeader("Content-Type", contentType);\n      res.setHeader(\n        "Content-Disposition",\n        `attachment; filename="${fileName}"`\n      );\n\n      // Send the file and ensure the response is complete before file cleanup\n      res.send(data);\n    } catch (err) {\n      next(err);\n    }\n  },\n}\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js",metastring:'title="src/api/routes/datasets.route.js"',title:'"src/api/routes/datasets.route.js"'},'router.get(\n  "/:idDataset/table/:idTable/export",\n  asyncMiddleware(DatasetsController.exportTable),\n);\nrouter.get(\n  "/:idDataset/table/:idTable/code",\n  asyncMiddleware(DatasetsController.exportTableCode),\n);\n')))),(0,r.kt)("h3",{id:"2-create"},"2. Create"),(0,r.kt)(o.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"autoAnnotationCreate",label:"Automatic Annotation",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js",metastring:'title="src/api/services/newGlobalAction/newGlobalAction.js"',title:'"src/api/services/newGlobalAction/newGlobalAction.js"'},"...\n"))),(0,r.kt)(s.Z,{value:"exportTableCreate",label:"Export Table",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js",metastring:'title="src/api/services/export/export.service.js"',title:'"src/api/services/export/export.service.js"'},'import { parse } from "json2csv";\nimport { spawn } from "child_process";\nimport path from "path";\nimport fs from "fs";\n\nconst ExportService = {\n  rawJson: async ({ columns, rows }) => {\n    return Object.keys(rows).map((rowId) => {\n      const colIds = Object.keys(rows[rowId].cells);\n\n      return colIds.reduce((acc, colId) => {\n        acc[columns[colId].label] = rows[rowId].cells[colId].label;\n        return acc;\n      }, {});\n    });\n  },\n  csv: async ({ columns, rows }) => {\n    const jsonData = await ExportService.rawJson({ columns, rows });\n    return parse(jsonData);\n  },\n  w3c: async ({ columns, rows, keepMatching = false }) => {\n    const getMetadata = (metadata = [], keepMatching) => {\n      if (keepMatching) {\n        return metadata\n          .filter((meta) => meta.match)\n          .map(({ name, ...rest }) => ({\n            name: name.value,\n          ...rest,\n          }));\n      }\n      return metadata.map(({ name, ...rest }) => ({\n        name: name.value,\n        ...rest,\n      }));\n    };\n\n    const firstRow = Object.keys(columns).reduce((acc, colId, index) => {\n      const { id, status, context, metadata, annotationMeta, ...propsToKeep } =\n        columns[colId];\n\n      const standardContext = Object.keys(context).reduce((accCtx, prefix) => {\n        const { uri } = context[prefix];\n        return [...accCtx, { prefix: `${prefix}:`, uri }];\n      }, []);\n\n      acc[`th${index}`] = {\n        ...propsToKeep,\n        metadata:\n          metadata.length > 0\n            ? [\n                {\n                  ...metadata[0],\n                  ...(metadata[0].entity && {\n                    entity: getMetadata(metadata[0].entity, keepMatching),\n                  }),\n                },\n              ]\n            : [],\n        context: standardContext,\n      };\n      return acc;\n    }, {});\n\n    const rest = Object.keys(rows).map((rowId) => {\n      const { cells } = rows[rowId];\n      return Object.keys(cells).reduce((acc, colId) => {\n        const { id, metadata, annotationMeta, ...propsToKeep } = cells[colId];\n\n        acc[colId] = {\n          ...propsToKeep,\n          metadata: getMetadata(metadata, keepMatching),\n        };\n        return acc;\n      }, {});\n    });\n\n    return [firstRow, ...rest];\n  },\n  semtParser: async ({ id, datasetId, format = "python" }) => {\n    return new Promise((resolve, reject) => {\n      let outputFilePath = null;\n      try {\n        // Get the log file path for the dataset and table\n        const logFilePath = path.join(\n          process.cwd(),\n          "public",\n          "logs",\n          `logs-${datasetId}-${id}.log`,\n        );\n\n        // Check if log file exists\n        if (!fs.existsSync(logFilePath)) {\n          return reject(\n            new Error(\n              `Log file not found for dataset ${datasetId} and table ${id}`,\n            ),\n          );\n        }\n\n        // Just use a simple default table name - the user will change it anyway when running the code\n        const tableFilePath = "table_1.csv";\n\n        // Path to semTParser executable (should be in public folder)\n        const semtParserPath = path.join(process.cwd(), "public", "semTParser");\n\n        // Generate output filename with timestamp\n        const timestamp = new Date()\n          .toISOString()\n          .replace(/:/g, "-")\n          .replace(/\\..+/, "");\n        const outputFileName =\n          format === "python"\n            ? `base_file_${timestamp}.py`\n            : `base_notebook_file_${timestamp}.ipynb`;\n\n        // Execute semTParser\n        const semtParser = spawn(semtParserPath, [\n          "--log-file",\n          logFilePath,\n          "--table-file",\n          tableFilePath,\n          "--format",\n          format,\n        ]);\n\n        let outputData = "";\n        let errorData = "";\n\n        semtParser.stdout.on("data", (data) => {\n          outputData += data.toString();\n        });\n\n        semtParser.stderr.on("data", (data) => {\n          errorData += data.toString();\n        });\n\n        semtParser.on("close", (code) => {\n          if (code !== 0) {\n            console.error(`semTParser exited with code ${code}`);\n            console.error(`Error output: ${errorData}`);\n            return reject(\n              new Error(`semTParser failed with code ${code}: ${errorData}`),\n            );\n          }\n\n          // Extract file path from semTParser output\n          const outputMatch = outputData.match(/file created at: (.+)$/m);\n          if (!outputMatch || !outputMatch[1]) {\n            return reject(\n              new Error(\n                "Could not determine output file path from semTParser output",\n              ),\n            );\n          }\n\n          outputFilePath = outputMatch[1].trim();\n\n          // Read the generated file with proper encoding\n          fs.readFile(outputFilePath, "utf8", (err, data) => {\n            if (err) {\n              // Clean up the file even if we couldn\'t read it\n              if (outputFilePath) {\n                fs.unlink(outputFilePath, () => {\n                  console.log(\n                    `Cleaned up file after read error: ${outputFilePath}`,\n                  );\n                });\n              }\n              return reject(\n                new Error(`Failed to read generated file: ${err.message}`),\n              );\n            }\n            \n            // Schedule file deletion with a slight delay to ensure response is complete\n            setTimeout(() => {\n              fs.unlink(outputFilePath, (unlinkErr) => {\n                if (unlinkErr) {\n                  console.warn(\n                    `Warning: Failed to delete temporary file ${outputFilePath}: ${unlinkErr.message}`,\n                  );\n                } else {\n                  console.log(\n                    `Successfully deleted temporary file: ${outputFilePath}`,\n                  );\n                }\n              });\n            }, 1000); // 1 second delay to ensure response is complete\n\n            // Return the file content and metadata\n            resolve({\n              data,\n              fileName: outputFileName,\n              filePath: outputFilePath,\n              contentType:\n                format === "python" ? "text/x-python" : "application/json",\n              });\n          });\n        });\n      } catch (error) {\n        // Clean up the output file if it exists and we encounter an error\n        if (outputFilePath && fs.existsSync(outputFilePath)) {\n          try {\n            fs.unlinkSync(outputFilePath);\n            console.log(`Cleaned up file after error: ${outputFilePath}`);\n          } catch (cleanupError) {\n            console.warn(\n              `Failed to clean up file: ${outputFilePath}`,\n              cleanupError,\n            );\n          }\n        }\n        reject(error);\n      }\n    });\n  },\n};\n\nexport default ExportService;\n')))))}p.isMDXComponent=!0}}]);